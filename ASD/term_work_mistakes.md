1. "Получим словарь, мощность которого будет меньше оригинального (пусть мощность равна L).", а дальше - ", L - максимальная длина слова в словаре" - конфликт обозначений.
2. "O(M * len(Mi) * N)" - что означают эти буквы и почему сложность именно такая - не написано. Да и вообще понять детали алгоритма после получения словаря анаграмм не представляется возможным по вашему описанию.
3. То же самое можно сказать про третий алгоритм. Подробностей недостаточно. Алгоритм Ахо-Корасик не описан. Если агмноорст - анаграмма изначального слова, то как найти по нему анаграмму "гор"? Ведь придется буквы пропускать - и тут явно уже будет не константная сложность.
4. Про "константную сложность". Формально можно принять размер словаря как константу.  И даже размер входного слова можно сверху ограничить. Но все-таки это не совсем константы, а для словаря, вдобавок - это еще и довольно большое число.  Поэтому в оценке сложности надо указывать подробный ответ. Более того, конкретно в вашем случае стоит разделить сложность препроцессинга словаря и сложность поиска одного слова.
5. Не забывайте про использование памяти - оно тоже должно быть в теоретической части
6. Формальная постановка задачи не очень корректна - ищете вы все таки не подслова, да и слишком размыта.
7.Секция "преимущества программы" довольно спорная: часть "преимуществ" - не преимущества вовсе, часть - требуется условием/алгоритмом, часть - просто факты.
8. Обсуждали вроде лично, что русский язык тоже надо поддерживать (вам нужны сведения по wstring?)
9. Пример с выходными данными стоит проверить - сомневаюсь, что все слова там настоящие. Например amin в оксфордском словаре нет, а ing - это суффикс, а не слово. Ну и зачем такое дичавое оформление - непонятно.
10. В качестве "преимуществ" указана поддержка нескольких файлов, а в документации по выполнению на входе только 1 файл. (На мой взгляд - это очень сомнительное преимущество, которое противоречит условию дз, так что я бы поддержку нескольких файлов удалил бы)
11. Ваша программа может работать только с 1 словарем, более того, путь к нему захардкожен в коде программы. Путь к словарю должен передаваться как входные данные. Тоже самое касается и файла с логом.
12. Не описана процедура получения/составления словаря.
13. Описаны явно не все использованные структуры данных.
14. В оценке сложности написана какая-то дичь. В этом разделе надо подробно пройтись по всей цепочке вызовов вашей программы, оценить сложность каждого шага и посчитать итоговую сложность. Особенно внимательно стоит оценить сложность вашего метода "AhoCorasick" (возможно вы узнаете много нового о реальной сложности алгоритма)
15. По памяти - тоже стоит получше написать.
 
 -----
По коду:
1. Файлы почему-то принципиально не закрываете.
2. Глобальная переменная std::wstring isItString = L"WORD"; в добавок еще и непонятно зачем.
3. SearchAlgorithm::substring - написано плохо, будет некорректно работать в некоторых случаях, что делает - непонятно (особенно "помогают" названия переменных a,b,str1,str2 и т.п.), проверить вхождение одной строки в другую можно стандартными средствами и более эффективно (по это даже есть задача в ДЗ к семинарам)
3. Все плохо с именованием переменных/методов.
4. Все плохо с инкапсуляцией - например, почему searchWords работает с wofstream? А если не нужен вывод в файл?
5. SearchAlgorithm у вас столько всего много делает - и словарь ищет, и слова проверяет. Не много ли у него функций?
6. С учетом п.11 checkDir, в котором понаписано дичи, можно будет смело удалить.
7. Хранение словаря в куче мелких файлов - весьма неэффективно с точки зрения нагрузки на файловую систему. Лучше бы разделить ваш словарь на несколько блоков, которые грузить в память (или вообще хранить в одном файле в специальном формате и сразу грузить в хорошую структуру данных).

4. Не понимаю, насколько подробно это нужно описывать и что значит «не совсем константы»?
8. Если есть возможность, скиньте пожалуйста материал и/или примеры для работы с русским языком и wstring, потому что я вертел это все и так, и сяк. Если сами строки хорошо работают с кириллицей, то уже обработка букв с wchar_t - это жесть, там никакие изменения кодировок и локалей не помогают.
9. Все, что выводится - это настоящий словарь английского языка, исходник лежит в репозитории, это все реальные слова. Я сам удивился, но да, оказывается все эти слова есть, и если в оксфордском словаре их нет, то в мультитране все находится: «amin» - это амин (флотореагент), ing - не только суффикс, но это еще и «луг, пастбище». Но при необходимости я могу, конечно, или отредактировать, или поискать другой словарь.
10. В задании написано «Программа принимает входные данные в виде одного или нескольких текстовых файлов», я подумал, что будет правильно сделать сразу несколько входных файлов. Ошибку понял, исправлю
13. Насколько подробно описывать структуры? То есть мне каждый тип переменной брать, или только касаемо алгоритмов, или по какому критерию это выбирать?
14. Насчет Ахо-Корасика - у меня, конечно, не совсем такой алгоритм получился, я не углублялся в тему автоматов, потому что мы это не проходили и я не уверен, что пойму все правильно. Мне это лучше исправить или оставить как есть, расписав подробнее?
 
Код:
2. std::wstring isItString = L«WORD» необходимо для адекватного вывода, у меня есть проверка на то, подается ли на вход целая строка из нескольких слов, или там всего одного слово, в зависимости от этого у меня выводится «word» или «string». Но вы указали, что в выходном файле у меня в принципе «дичь», поэтому я от этого избавлюсь.
7. К сожалению, на файловую систему нагрузка действительно большая, но зато программе не нужно ничего грузить ни в память, ни в какую-либо структуру, и все это работает быстрее, чем если бы сначала считывался весь словарь, создавалась структура, а потом только выполнялся алгоритм. Возможно существует более оптимальный вариант? Если да, можете подсказать, пожалуйста, я ничего лучше реализованного подхода не придумал.

----
4. Помните, как вы разбиралис ложность поиска в ширину? Примерно на таком уровне.
Сложность не совсем константная - потому что она, очевидно, будет отличаться для русского, английского и корейского словаря, причем довольно существенно.
8. В принципе у вас вроде все нормально - вроде везде правильные типы и литералы. Только надо проверить, что везде используются функции для работы именно с wstring - towlower вместо tolower, например. Вообще в вашем случае проще все отдебажить и решать уже конкретные проблемы.
9. Ага, ок, видимо просто словарь такой нашли.
13. Всякую вспомогательную мелочь описывать не надо. А вот ключевые для алгоритма - надо. То же префискное дерево - вполне себе структура и его точно надо описать.
14. Это уже стоит решить после исправления теоретической части (где вам надо будет описать, как теоретически должен алгоритм работать), оценки сложности/краткого описания программы (где вы лучше поймете, как он реально работает). Сначало нужно понять, что делать, как делать, и что не так с текущей реализацией.
 
Код:
2. Ну тут еще с точки зрения кода довольно грустно - если бы у вас 2 экземпляра класса были бы одновременно, то все было бы плохо.
7. Тут опять же стоит разделять препроцессинг и отработку алгоритма. Да, грузить весь словарь дольше, чем куски, но зато после того, как словарь загружен, ответ на 1000 разных запросов будет дан быстрее. Собственно мне особо к уже написанным вариантам добавить нечего.